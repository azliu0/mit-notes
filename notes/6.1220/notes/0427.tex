\section{April 27, 2023}

\subsection{Exponential Time Algorithms}

\begin{definition}
\deflabel

$O^*(f(n)) = f(n)\cdot \text{poly}(n)$. 
\end{definition}

Analogously to the way that normal big-$O$ notation ignores constant time factors, $O^*$ notation ignores polynomial time factors, since these are considered ``cheap'' when doing exponential time analysis. 

\subsection{Subset Sum}

\begin{itemize}
    \item input: $A = \{a_1, \hdots, a_n\}$ and target $t$
    \item output: whether there is some $S\subseteq A$ such that $\sum_{s\in S}s=t$.
\end{itemize}

The brute force algorithm is to try every possible subset. This is $O^*(2^n)$. 

To improve this runtime, we can also ``meet in the middle''. Consider splitting $A$ into two lists of size $n/2$. Now construct $L_1$ which has the sum of all possible subsets of the first list, which has size $2^{n/2}$. Let $L_2$ be the set of all $t-w$ for all possible sums $w$ of the second list, which has size $2^{n/2}$. Now, the problem reduces to finding a common element between $L_1$ and $L_2$. Using hashing, sorting, or otherwise, this can be done in $O(n2^{n/2})\in O^*(2^{n/2})$.  
\begin{itemize}
    \item Brute force algorithm: $O^*(2^n)$ time, $O^*(1)$ space
    \item Meet in the middle: $O^*(2^{n/2})$ time, $O^*(2^{n/2})$ space. 
    \item Schroppel-Shamir: $O^*(2^{n/2})$ time, $O^*(2^{n/4})$ space.
    \item Nederlof-Wegrzycki: $O^*(2^{n/2})$ time, $O^*(2^{0.0249999n})$ space. 
    \item Bansal, Garg, Nederlof: $O^*(2^{0.86n})$ time, poly space.
\end{itemize}

\subsection{3SAT}

\begin{itemize}
    \item input: $3$CNF formula $F$ on $n$ variables and $m$ clauses
    \item output: is there a boolean assignment to the $n$ variables satisfying $F$?
\end{itemize}

The brute force algorithm is to try every possible assignment of variables, which is $O^*(2^n)$. 

Branch on variables: 
\begin{itemize}
    \item Plug in $x_1=1$ and recurse. If the result was satisfiable, return this result.
    \item Otherwise, the result was not satisfiable, then try $x_1=0$ and recurse. Return the result. 
\end{itemize}

Each ``branch'' reduces the number of variables by $1$, so the total runtime satisfies $T(n)\leq 2T(n-1)+O^*(1)\in O^*(2^n)$. 

\begin{theorem}
\claimlabel

$2$-SAT has a polynomial time algorithm. 
\end{theorem}

Intuition: each branch resolves all clauses in the same connected component.

\begin{example}
\exlabel

Improved algorithm.
\end{example}

Using this fact, we can create a new branching algorithm: 
\begin{itemize}
    \item Simplify $F$ by removing redundant variables in clauses. If $F$ is a $2$-CNF, then solve $F$ in $O^*(1)$
    \item Otherwise, pick a clause with three distinct variables $(\ell_1, \ell_2, \ell_3)$. There are exactly $7<2^3$ assignments which satisfies this clause; branch on these assignments, and recurse. 
    \item Now, the total depth of the recursion tree is at most $n/3$, since we guarantee the assignment of three distinct variables at each branch. This implies that the total number of nodes is $O(7^{n/3})$. In each node, we perform $O^*(1)$ work to reduce the formula, so our runtime is $O^*(7^{n/3})\in O^*(1.91^n)$. 
\end{itemize}

\begin{example}
\exlabel

Even more improved algorithm.
\end{example}

Instead of directly branching on all $7$ possible valid triples $(\ell_1, \ell_2, \ell_3)$, we can branch one at a time: 
\begin{itemize}
    \item try $\ell_1=1$ and recurse. If this works, return that it works.
    \item otherwise, try $\ell_1=0$, $\ell_2=1$ and recurse. If this works, return that it works.
    \item otherwise, try $\ell_1=0$, $\ell_2=0$, $\ell_3=1$ and recurse. return the result.
\end{itemize}
Like the last algorithm, this accounts for all possible triples $(\ell_1, \ell_2, \ell_3)$, but does so by branching one at a time, which is slightly more efficient. The runtime is 
\[T(n)\leq T(n-1)+T(n-2)+T(n-3)+O^*(1).\]

If we guess $T(n)\in O^*(a^n)$, this reduces to $a^3=a^2+a+1$, which gives $a\leq 1.84$, so the total runtime is $T(n)\in O^*(1.84^n)$. This is OK. The best known algorithm is $O^*(1.308^n)$. 