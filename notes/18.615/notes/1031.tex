\section{October 31, 2023}

Last time: 
\[\EE[X|Y] = \sum_y \EE[X|Y=y]\mathbbm{1}_{Y=y}.\]
Also, 
\[\EE[f(Y)|Y] = f(Y),\]
and
\[\EE[X|Y] = \EE[X],\]
if $X,Y$ independent, and
\[\EE[Xf(Y)|Y] = \EE[X|Y]f(Y),\]
and
\[\EE[\EE[X|f(Y)]|Y] = \EE[\EE[X|Y]|f(Y)] = \EE[X|f(Y)].\]

\subsection{Martingales}

\begin{definition}
\deflabel

A $\RR$-valued stochastic process $X_i$ is a \ac{martingale} if 
\begin{itemize}
	\item $\EE(\vert X_i\vert) < \infty$
	\item $\EE(X_{i+1}|X_i,\hdots,X_1)=X_i$
\end{itemize}
\end{definition}

\begin{definition}
\deflabel

$Y_i$ is a martingale with respect to $X_i$ if 
\begin{itemize}
	\item $\EE[\vert Y_i\vert] < \infty$
	\item $Y_i$ is a function of $X_1, \hdots, X_i$.
	\item $\EE[Y_{i+1}|X_1,\hdots, X_i] = Y_i$. 
\end{itemize}
\end{definition}

\begin{theorem}
\proplabel

If $Y_i$ is a martingale wrt $X_i$, then $Y_i$ is a martingale. 
\end{theorem}

\begin{proof}
Since all $Y_i$ are fns of $X_1, \hdots, X_i$, the tower laws imply that 
\begin{align*}
	\EE[Y_{i+1}|Y_i,\hdots,Y_1] &= \EE[\EE[Y_{i+1}|X_1,\hdots,X_i]|Y_1,\hdots, Y_i] \\
															&= \EE[Y_{i+1}|X_1, \hdots, X_i] = Y_i.
\end{align*}
\end{proof}

\begin{example}
\exlabel

Let $X_i$ be i.i.d with $\EE[X_i]=0$ and $\EE[X_i^2] = 1$. If $S_n = X_1 + \hdots + X_n$, then $M_n = S_n^2 - n$ is a martingale wrt $X_i$. 
\end{example}

$\EE[\vert S_i\vert] < \infty$, and $S_i$ is a fn of $X_1, \hdots, X_i$, so the first two conditions hold. For the third condition, 
\begin{align*}
	\EE[M_{i+1}|X_1,\hdots, X_i] &= \EE[(X_i+X_i)^2 - (i+1) | X_1, \hdots, X_i]\\
															 &= \EE[S_i^2 + 2S_iX_{i+1}+X_{i+1}^2 - i - 1 | X_1, \hdots, X_i] \\
															 &= S_i^2 - i = M_i. 
\end{align*}

\begin{theorem}
\lemlabel

If $X_i, Y_i$ are independent martingales, then $X_i+Y_i$ is also a martingale.
\end{theorem}

\begin{proof}
If $X_i,Y_i$ are finite, then so is $X_i+Y_i$, so the first condition holds. Also, 
\[\EE[X_{i+1}+Y_{i+1}|\{X_j\}_{j\leq i}, \{Y_j\}_{j\leq i}] = X_i+Y_i\] 
by the linearity of expectation, so the second condition also holds. 
\end{proof}

\begin{example}
\exlabelname{Doob martingale}

Let $Y, X_1, X_2, \hdots$ be r.v.s Then, $M_i = \EE[Y|X_1, \hdots, X_i]$ is a martingale. 
\end{example}

From the tower law, 
\[\EE[M_{i+1}|X_1, \hdots, X_n] = \EE[\EE[Y|X_1, \hdots, X_i]|X_1, \hdots, X_i] = \EE[Y|X_1, \hdots, X_i] = M_i.\] 

\begin{theorem}
\proplabel

Let $M_i$ be a martingale wrt $X_i$. 

\begin{enumerate}
	\item $\EE[M_1] = \EE[M_i]\forall i$
	\item $\EE[M_i|X_1,\hdots,X_j] = M_j$ if $j\leq i$. 
	\item Increments are uncorrelated, i.e., 
		\[\EE[(M_j-M_i)(M_{j'} - M_{i'})] = 0\]
		if $i < j < i' < j'$. 
\end{enumerate}
\end{theorem}

\begin{proof}
\begin{enumerate}
	\item 
		\[\EE[M_i] = \EE[\EE[M_{i-1} | X_1, \hdots, X_{i-1}]] = \EE[M_{i-1}] = \hdots. \]
	\item 
		\begin{align*}
			\EE[M_i|X_1, \hdots, X_j] &= \EE[\EE[M_i|X_1, \hdots, X_{i-1}]|X_1, \hdots, X_j] \\
																&= \EE[M_{i-1}|X_1, \hdots, X_j] \\
																&= \vdots \\
																&= \EE[M_{j+1} | X_1, \hdots, X_j] = M_j. 
		\end{align*}	
	\item Suffices to assume $j=i+1$ and $j' = i'+1$. 
		\begin{align*}
			\EE[(M_{i+1}-M_i)(M_{i'+1}-M_{i'})] &= \EE[\EE[(M_{i+1}-M_i)(M_{i'+1}-M_{i'})]|X_1, \hdots, X_{i+1}] \\
																					&= \EE[(M_{i+1}-M_i)]\EE[(M_{i'+1}-M_{i'}) | X_1, \hdots, X_{i+1}] = 0. 
		\end{align*}
\end{enumerate}
\end{proof}


\begin{theorem}
\thmlabelname{Martingale convergence theorem}

Let $M_i$ be a martingale with $\EE[\vert M_i\vert] \leq c < \infty$. Then 
\[M_{\infty} = \lim_{i\rightarrow \infty}M_i\]
exists a.s, and $\EE[M_{\infty}] < \infty$.  
\end{theorem}

\begin{example}
\exlabelname{Polya's urn}

We have an urn with two types of objects, Reeses and Gumdrops. At each time step, we uniformly pick one item from the urn and replace it with $2$ of the same type of object. The urn starts with one of each type of object. 
\end{example}

Let $R_i,G_i$ be the number of Reeses and Gumdrops at time $i$. We want to find 
\[\lim_{i\rightarrow \infty}\frac{R_{i}}{i+1},\] 
which is the proportion of Reeses in the jar at time $i$. We will show that 
\[\frac{R_i}{i+1}\cas \Unif[0,1].\] 

\begin{theorem}
\claimlabel

$R_i$ is uniform on $\{1,\hdots, i\}$. 
\end{theorem}

\begin{proof}
We use induction. $i=1$ works. 
\[\PP[R_{i+1}=k] = \PP[R_i=k]\frac{k}{i+1} + \PP[R_i=k-1]\frac{k-1}{i+1} = \frac{1}{i}\frac{i+1-k}{i+1} + \frac{1}{i}\frac{k-1}{i+1} = \frac{1}{i+1}.\]
\end{proof}

This implies that 
\[\lim_{i\rightarrow \infty}\PP\left(\frac{R_i}{i+1}\in (a,b)\right) = b-a\]
for $0\leq a < b\leq 1$. Now, let's show a.s. convergence. 
\begin{theorem}
\claimlabel

\[M_i = \frac{R_i}{i+1}\] 
is a martingale. 
\end{theorem}

\begin{proof}
Moments are finite, so it suffices to check:
\begin{align*}
	\EE\left[ \frac{R_{i+1}}{i+2} \vert R_1, \hdots, R_i\right] &= \EE\left[ \frac{R_{i+1}}{i+2}\vert R_i\right] \\
																													&= \frac{R_i + \PP[\text{chooses }R | R_i]}{i+2} \\
																													&= \frac{R_i + R_i/(i+1)}{i+2} = \frac{R_i}{i+1}.
\end{align*}
\end{proof}

If $M_i\geq 0$, then $\EE[\vert M_i\vert] = \EE[M_i] = \EE[M_i]$. 
