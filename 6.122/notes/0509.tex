\section{May 9, 2023}

\subsection{Sublinear Algorithms}

\begin{definition}
\deflabel

Sublinear algorithms don't need to read the entire input to produce an answer.
\end{definition}

Exact sublinear algorithms are usually bad. For example, consider the triangle detection problem: 
\begin{itemize}
    \item The input is a graph $G$ in matrix format. Output YES if there is a triangle and NO otherwise. 
\end{itemize}

If $G$ is completely bipartite, there are no triangles. If $G$ is completely bipartite + one edge, then there are triangles. This shows that it is impossible to consistently produce a correct answer to this problem without reading $\Omega(n^2)$ of the input. 

A more reliable approach is to try to approximate the answer:
\begin{itemize}
    \item \ac{Classical approximations} are used for optimization problems. An $\alpha$-approximation factor indicates an answer within $\alpha$ of OPT.
    \item \ac{Property testing} is an approximation for decision problems. This should always return YES on a YES-instance. This should return NO on NO-instances that are ``very far'' from YES-instances, with some high probability. It can return anything on other instances. 
\end{itemize}

\subsection{Diameter of a point set}

This problem demonstrates a classical approximation. 

\begin{itemize}
    \item Input: $n\times n$ matrix $D$ where $D_{i,j}$ denotes a distance between $i$ and $j$. This means that $D$ is symmetric and satisfies the triangle inequality, i.e., 
    \[D_{i,j}\leq D_{i,k} + D_{k,j}.\]
    \item Output: $D^*$ which is the largest distance between two points, i.e., the maximum entry of the matrix.
\end{itemize}

The input has size $N=n^2$. Any sublinear algorithm is $o(N)\in o(n^2)$. An algorithm with approximation factor $c$ should satisfy 
\[\frac{D^*}{c}\leq \tilde{D} \leq D^*.\]

\hrulebar 

Algorithm: 
\begin{itemize}
    \item pick an index $i^*\in [n]$.
    \item read the $i^*$th row, output $\tilde{D} = \max_{j}D_{i^*,j}.$
\end{itemize}

The runtime is $O(n)$, so it is sublinear. We claim $\tilde{D}\geq D^*/2$. If the true diameter has a point in the $i^*$th row, then $\tilde{D}=D^*$. Otherwise, $D_{i^*,a}+D_{i^*,b}\geq D_{a,b}=D^*$, so $\max\{D_{i^*,a}, D_{i^*,b}\}\geq D^*/2$. Therefore, this algorithm is a $2$-approximation. 

\subsection{Testing for Connectedness}

This problem demonstrates a property testing approximation. 

\begin{itemize}
    \item Input: $G=(V,E)$ on $n$ vertices with maximum degree $d$ in an adjacency list format. 
    \item Output: whether or not $G$ is connected. 
\end{itemize}

\noindent Our approximation will return: 
\begin{itemize}
    \item YES if $G$ is connected
    \item NO if $G$ is not $\varepsilon$-close to being connected
    \item anything otherwise
\end{itemize}

\begin{definition}
\deflabel

$G$ is $\varepsilon$-close to being connected if it is possible to add $\varepsilon nd$ edges to make $G$ connected. 
\end{definition}

\begin{theorem}
\claimlabel

if $G$ is not $\varepsilon$-close to connected, then $G$ has $>\varepsilon dn$ connected components.
\end{theorem}

\begin{proof}
If not, then we can add edges between them. 
\end{proof}

\begin{theorem}
\claimlabel

if $G$ is not $\varepsilon$-close to connected, then $G$ has $\geq \varepsilon dn/2$ connected components of size at most $2/(\varepsilon d)$.
\end{theorem}

\begin{proof}
The number of connected components is at least $\varepsilon dn$. So if we suppose otherwise, then the number of connected components with size $\geq 2/(\varepsilon d)$ is $> \varepsilon dn/2$. On the other hand, the total number of vertices is $\leq n$, so this is a contradiction.    
\end{proof}

\begin{theorem}
\claimlabel

If $G$ is not $\varepsilon$-close to connected, at least $\varepsilon nd/2$ vertices are in small connected components. 
\end{theorem}

\begin{proof}
Follows from the previous claim. 
\end{proof}

\hrulebar

Algorithm: let $c\geq 2$ be some constant. Repeat $c/(\varepsilon d)$ times: 
\begin{itemize}
    \item pick a node $s$ uniformly at random
    \item run BFS from $s$ until either $2/(\varepsilon d)$ have been seen, or a CC of size $<2/(\varepsilon d)$ has been found. In the first case, continue running the algorithm. In the second case, return NO. 
    \item If the algorithm reaches the end of its iterations, return YES. 
\end{itemize}

The runtime is $O(1/(\varepsilon d)\cdot (2/(\varepsilon d) + 2/\varepsilon))\in O(1/(d\varepsilon^2))$, which is constant time, so this algorithm is sublinear.

\begin{theorem}
\claimlabel

If $G$ is connected, the algorithm will correctly always return YES. Otherwise, it returns NO with probability at least $3/4$. 
\end{theorem}

\begin{proof}
The YES direction is true. Now suppose $G$ is not $\varepsilon$-close to connected. By the third claim, there are $>\varepsilon dn/2$ nodes in a small component, so the probability that $s$ is in a small CC in one iteration is $ > \varepsilon d/2$. Therefore, the probability that none of the iterations sample a vertex in a small component is $(1-\varepsilon d/2)^{2c/(\varepsilon d)}\leq (1/e)^c\leq 1/4$. 
\end{proof}

\subsection{Sortedness of a List}

\begin{itemize}
    \item Input: List $L=\{x_0, \hdots, x_{n-1}\}.$
    \item Output: YES if $L$ is sorted, NO if the list is not $\varepsilon$-close from sorted with high probability. 
\end{itemize}

\begin{definition}
\deflabel

A list of length $n$ is $\varepsilon$-close to sorted if it is possible to delete $n\varepsilon$ elements and get a sorted list.
\end{definition}

\hrulebar

Algorithm: think of the list as a binary search tree. Pick a random index $i$ and search for $x_i$ by binary searching the list. Return YES if we end up at index $i$ with no inconsistencies found during the search, and NO otherwise. 